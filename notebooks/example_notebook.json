{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Psychedelic Gradient Analysis\n",
    "\n",
    "This notebook provides a quick introduction to using the psychedelic gradient analysis toolkit.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll walk through:\n",
    "1. Loading and preprocessing fMRI data\n",
    "2. Computing functional connectivity matrices\n",
    "3. Extracting connectivity gradients\n",
    "4. Performing statistical comparisons\n",
    "5. Creating visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our analysis modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from analysis.connectivity_analysis import ConnectivityAnalyzer\n",
    "from analysis.gradient_analysis import GradientAnalyzer\n",
    "from analysis.statistical_analysis import ConnectivityStatistics\n",
    "from visualization.plotting import ConnectivityPlotter, GradientPlotter\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Analyzers\n",
    "\n",
    "First, let's set up our analysis objects with the Schaefer 100-parcel atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connectivity analyzer\n",
    "conn_analyzer = ConnectivityAnalyzer(\n",
    "    atlas_name='schaefer',\n",
    "    n_rois=100,\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "# Initialize gradient analyzer\n",
    "grad_analyzer = GradientAnalyzer(\n",
    "    n_components=10,\n",
    "    approach='pca',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize plotters\n",
    "conn_plotter = ConnectivityPlotter()\n",
    "grad_plotter = GradientPlotter()\n",
    "\n",
    "print(f\"Connectivity analyzer initialized with {len(conn_analyzer.labels)} ROIs\")\n",
    "print(f\"Gradient analyzer set to compute {grad_analyzer.n_components} components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Example Data\n",
    "\n",
    "For this example, we'll create synthetic data that mimics real fMRI connectivity patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example connectivity data\n",
    "np.random.seed(42)\n",
    "n_subjects = 20\n",
    "n_rois = 100\n",
    "\n",
    "def create_realistic_connectivity(n_subjects, n_rois, condition_effect=0.0):\n",
    "    \"\"\"Create realistic connectivity matrices with network structure.\"\"\"\n",
    "    matrices = []\n",
    "    \n",
    "    for subj in range(n_subjects):\n",
    "        # Create base connectivity with network structure\n",
    "        base_matrix = np.random.randn(n_rois, n_rois) * 0.3\n",
    "        \n",
    "        # Add network structure (higher connectivity within networks)\n",
    "        network_size = n_rois // 7  # 7 networks\n",
    "        for net in range(7):\n",
    "            start_idx = net * network_size\n",
    "            end_idx = min((net + 1) * network_size, n_rois)\n",
    "            base_matrix[start_idx:end_idx, start_idx:end_idx] += 0.5\n",
    "        \n",
    "        # Make symmetric\n",
    "        base_matrix = (base_matrix + base_matrix.T) / 2\n",
    "        \n",
    "        # Set diagonal to 1\n",
    "        np.fill_diagonal(base_matrix, 1)\n",
    "        \n",
    "        # Add condition effect\n",
    "        if condition_effect != 0:\n",
    "            effect_matrix = np.random.randn(n_rois, n_rois) * condition_effect\n",
    "            effect_matrix = (effect_matrix + effect_matrix.T) / 2\n",
    "            base_matrix += effect_matrix\n",
    "        \n",
    "        matrices.append(base_matrix)\n",
    "    \n",
    "    return matrices\n",
    "\n",
    "# Create connectivity data for two conditions\n",
    "print(\"Creating synthetic connectivity data...\")\n",
    "placebo_matrices = create_realistic_connectivity(n_subjects, n_rois, condition_effect=0.0)\n",
    "drug_matrices = create_realistic_connectivity(n_subjects, n_rois, condition_effect=0.1)\n",
    "\n",
    "print(f\"Created {len(placebo_matrices)} placebo matrices\")\n",
    "print(f\"Created {len(drug_matrices)} drug matrices\")\n",
    "print(f\"Matrix shape: {placebo_matrices[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Connectivity\n",
    "\n",
    "Let's visualize the average connectivity patterns for both conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average connectivity matrices\n",
    "placebo_mean = np.mean(placebo_matrices, axis=0)\n",
    "drug_mean = np.mean(drug_matrices, axis=0)\n",
    "\n",
    "# Plot connectivity matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Placebo connectivity\n",
    "im1 = axes[0].imshow(placebo_mean, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "axes[0].set_title('Placebo Mean Connectivity', fontsize=14)\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Drug connectivity\n",
    "im2 = axes[1].imshow(drug_mean, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "axes[1].set_title('Drug Mean Connectivity', fontsize=14)\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Difference\n",
    "difference = drug_mean - placebo_mean\n",
    "abs_max = np.max(np.abs(difference))\n",
    "im3 = axes[2].imshow(difference, cmap='RdBu_r', vmin=-abs_max, vmax=abs_max)\n",
    "axes[2].set_title('Drug - Placebo Difference', fontsize=14)\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Maximum connectivity difference: {abs_max:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute and Compare Gradients\n",
    "\n",
    "Now let's extract connectivity gradients and compare them between conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients for both conditions\n",
    "print(\"Computing gradients...\")\n",
    "\n",
    "placebo_gradients = []\n",
    "drug_gradients = []\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    # Compute gradients for placebo\n",
    "    placebo_grad = grad_analyzer.compute_gradients(placebo_matrices[i])\n",
    "    placebo_gradients.append(placebo_grad)\n",
    "    \n",
    "    # Compute gradients for drug\n",
    "    drug_grad = grad_analyzer.compute_gradients(drug_matrices[i])\n",
    "    drug_gradients.append(drug_grad)\n",
    "\n",
    "# Convert to arrays\n",
    "placebo_gradients = np.array(placebo_gradients)  # (n_subjects, n_rois, n_components)\n",
    "drug_gradients = np.array(drug_gradients)\n",
    "\n",
    "print(f\"Gradient array shape: {placebo_gradients.shape}\")\n",
    "print(\"Gradients computed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Gradients\n",
    "\n",
    "Let's visualize the first few gradient components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average gradients\n",
    "placebo_grad_mean = np.mean(placebo_gradients, axis=0)\n",
    "drug_grad_mean = np.mean(drug_gradients, axis=0)\n",
    "\n",
    "# Plot first 3 gradient components\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for comp in range(3):\n",
    "    # Placebo gradients\n",
    "    axes[0, comp].scatter(range(n_rois), placebo_grad_mean[:, comp], \n",
    "                         c=placebo_grad_mean[:, comp], cmap='viridis', s=30)\n",
    "    axes[0, comp].set_title(f'Placebo - Gradient {comp+1}', fontsize=14)\n",
    "    axes[0, comp].set_xlabel('ROI Index')\n",
    "    axes[0, comp].set_ylabel('Gradient Value')\n",
    "    \n",
    "    # Drug gradients\n",
    "    axes[1, comp].scatter(range(n_rois), drug_grad_mean[:, comp], \n",
    "                         c=drug_grad_mean[:, comp], cmap='viridis', s=30)\n",
    "    axes[1, comp].set_title(f'Drug - Gradient {comp+1}', fontsize=14)\n",
    "    axes[1, comp].set_xlabel('ROI Index')\n",
    "    axes[1, comp].set_ylabel('Gradient Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis\n",
    "\n",
    "Now let's perform statistical tests to identify significant differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform paired t-tests on gradients\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Test each gradient component\n",
    "n_components = 3  # Focus on first 3 components\n",
    "gradient_results = []\n",
    "\n",
    "for comp in range(n_components):\n",
    "    t_stats = []\n",
    "    p_values = []\n",
    "    \n",
    "    for roi in range(n_rois):\n",
    "        placebo_vals = placebo_gradients[:, roi, comp]\n",
    "        drug_vals = drug_gradients[:, roi, comp]\n",
    "        \n",
    "        t_stat, p_val = ttest_rel(drug_vals, placebo_vals)\n",
    "        t_stats.append(t_stat)\n",
    "        p_values.append(p_val)\n",
    "    \n",
    "    gradient_results.append({\n",
    "        'component': comp + 1,\n",
    "        't_statistics': np.array(t_stats),\n",
    "        'p_values': np.array(p_values)\n",
    "    })\n",
    "\n",
    "# Apply FDR correction\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "for result in gradient_results:\n",
    "    rejected, p_corrected = fdrcorrection(result['p_values'], alpha=0.05)\n",
    "    result['significant_mask'] = rejected\n",
    "    result['p_corrected'] = p_corrected\n",
    "    result['n_significant'] = np.sum(rejected)\n",
    "\n",
    "# Print summary\n",
    "for result in gradient_results:\n",
    "    comp = result['component']\n",
    "    n_sig = result['n_significant']\n",
    "    print(f\"Gradient {comp}: {n_sig}/{n_rois} significant ROIs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Statistical Results\n",
    "\n",
    "Let's create visualizations of our statistical findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot t-statistics for each gradient component\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, result in enumerate(gradient_results):\n",
    "    comp = result['component']\n",
    "    t_stats = result['t_statistics']\n",
    "    significant = result['significant_mask']\n",
    "    \n",
    "    # Plot t-statistics\n",
    "    colors = ['red' if sig else 'gray' for sig in significant]\n",
    "    axes[i].scatter(range(n_rois), t_stats, c=colors, s=30, alpha=0.7)\n",
    "    axes[i].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[i].set_title(f'Gradient {comp} T-Statistics\\n({result[\"n_significant\"]} significant ROIs)', \n",
    "                     fontsize=12)\n",
    "    axes[i].set_xlabel('ROI Index')\n",
    "    axes[i].set_ylabel('T-Statistic')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Gradient Correlations\n",
    "\n",
    "Let's examine the correlations between gradient components across conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations between conditions for each gradient\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for comp in range(3):\n",
    "    placebo_comp = placebo_grad_mean[:, comp]\n",
    "    drug_comp = drug_grad_mean[:, comp]\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[comp].scatter(placebo_comp, drug_comp, alpha=0.6, s=40)\n",
    "    \n",
    "    # Add correlation line\n",
    "    min_val = min(np.min(placebo_comp), np.min(drug_comp))\n",
    "    max_val = max(np.max(placebo_comp), np.max(drug_comp))\n",
    "    axes[comp].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "    \n",
    "    # Calculate and display correlation\n",
    "    correlation = np.corrcoef(placebo_comp, drug_comp)[0, 1]\n",
    "    axes[comp].text(0.05, 0.95, f'r = {correlation:.3f}', \n",
    "                   transform=axes[comp].transAxes, fontsize=14,\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    \n",
    "    axes[comp].set_xlabel(f'Placebo - Gradient {comp+1}')\n",
    "    axes[comp].set_ylabel(f'Drug - Gradient {comp+1}')\n",
    "    axes[comp].set_title(f'Gradient {comp+1} Correlation')\n",
    "    axes[comp].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "In this notebook, we've demonstrated the basic workflow for psychedelic gradient analysis:\n",
    "\n",
    "1. ✅ **Data Loading**: